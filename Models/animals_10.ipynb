{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dropout, Rescaling\n",
    "from tensorflow.keras.models import Sequential #Feed-Forward-NN\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt #Plot Images\n",
    "import os #Access files and folders\n",
    "import numpy as np #Calculations\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"GPUs detected: \", len(physical_devices))\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True) #Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"G:/Python/data/10_animals\" #Path to dataset\n",
    "height = 300; width = 300 #Rescale images in dataset to set size\n",
    "batch_size = 64 #determine batch size for training\n",
    "\n",
    "train = tf.keras.preprocessing.image_dataset_from_directory( #Loading training-data\n",
    "    path,\n",
    "    image_size=(height, width),\n",
    "    validation_split=0.25, #Determine how many images will be used for validation\n",
    "    subset=\"training\",\n",
    "    seed=123, #Shuffling and Transformation\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val = tf.keras.preprocessing.image_dataset_from_directory( #Loading validation-data\n",
    "    path,\n",
    "    image_size=(height, width),\n",
    "    validation_split=0.25,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "classes = train.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data-Augmentation\n",
    "data_aug = Sequential([ \n",
    "    tf.keras.layers.experimental\n",
    "    .preprocessing.Rescaling(1./255),\n",
    "\n",
    "    tf.keras.layers.experimental\n",
    "    .preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "\n",
    "    tf.keras.layers.experimental\n",
    "    .preprocessing.RandomRotation(0.3),\n",
    "\n",
    "    tf.keras.layers.experimental.preprocessing\n",
    "    .RandomZoom(height_factor=(-0.05, -0.15), width_factor=(-0.05, -0.15))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot random images from dataset\n",
    "data_iterator = train.as_numpy_iterator() \n",
    "batch = data_iterator.next()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(classes[batch[1][idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    InputLayer((height, width, 3)), #Input-Layer\n",
    "    data_aug, #Data Augmentation\n",
    "\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'), #Convolution-Layer\n",
    "    MaxPooling2D(), #Pooling-Layer\n",
    "    Dropout(0.25), #Dropout-Layer\n",
    "\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'), #Convolution-Layer\n",
    "    MaxPooling2D(), #Pooling-Layer\n",
    "    Dropout(0.25), #Dropout-Layer\n",
    "\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'), #Convolution-Layer\n",
    "    MaxPooling2D(), #Pooling-Layer\n",
    "    Dropout(0.25), #Dropout-Layer\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(classes), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'] #tracking for accuracy\n",
    ")\n",
    "\n",
    "model.summary() #overview of built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:/Users/maxis/Desktop/Proseminar - CNN/checkpoints/Checkpoint-{epoch:02d}--{val_accuracy:.02f}.h5\"\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', varbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state = f\"animals_10_{datetime.now().strftime('%H-%M-%S')}\"\n",
    "tensorboard = TensorBoard(log_dir = f\"C:/Users/maxis/Desktop/Proseminar - CNN/logdir/{model_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, validation_data=val, epochs=10, callbacks=[tensorboard, checkpoint]) #Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(\"G:/Python/data/img_from_google/cat1.jpg\", target_size=(height, width)) #Load image thats not already in the dataset\n",
    "\n",
    "plt.imshow(img) #Plot image\n",
    "plt.show()\n",
    "\n",
    "img = tf.keras.preprocessing.image.img_to_array(img) #Convert image into array\n",
    "img = np.expand_dims(img, axis=0) #Add dimensions to array to be processed by the model\n",
    "\n",
    "prediction = model.predict(img) #Model predicts class of image\n",
    "\n",
    "print()\n",
    "\n",
    "prediction_probabilities = tf.math.top_k(prediction, k=5) #Get top-5 predictions\n",
    "top_5_scores = prediction_probabilities.values.numpy().tolist() #Get top-5 probabilities\n",
    "dict_class_entries = prediction_probabilities.indices.numpy().tolist() #Get matching classes to probabilities\n",
    "for label, confidence in zip(dict_class_entries[0], top_5_scores[0]):\n",
    "    print(f\"Image predicted to be {classes[label]} with confidence of {round(confidence*100, 3)}%\") #Printing the class and probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(\"C:/Users/maxis/Desktop/Proseminar - CNN/Models\",\"animals_10_69_val_accuracy.h5\")) #Save the structure (weights etc.) of the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
